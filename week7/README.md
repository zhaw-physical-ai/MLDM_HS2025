# Week 7: Training Neural Networks

## Overview
This week focuses on training neural networks, including backpropagation, optimization techniques, and practical training strategies.

## Files

- **L07_Training_NNs.ipynb**: Main lab notebook covering neural network training concepts and implementation
- **Week_7_Backprop.ipynb**: Additional examples covering backpropagation algorithm (optional)

## Open directly the lab in Google Colab

<a href="https://colab.research.google.com/github/zhaw-physical-ai/MLDM_HS2025/blob/main/week7/L07_Training_NNs.ipynb" target="_blank">
  <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open Main Lab File In Colab" width="200"/>
</a><br></br>

For the additional notebooks with examples:

[![Run additional (voluntary) backpropagation examples notebook](https://img.shields.io/badge/Colab-Run%20additional%20(voluntary)%20backpropagation%20examples%20notebook-orange?logo=googlecolab)](https://colab.research.google.com/github/zhaw-physical-ai/MLDM_HS2025/blob/main/week7/Week_7_Backprop.ipynb)



## Learning Objectives
- Understand backpropagation algorithm and gradient computation
- Master optimization techniques for neural network training
- Implement effective training strategies
- Apply regularization techniques to prevent overfitting
- Learn batch normalization and other normalization techniques
- Understand learning rate schedules and adaptive optimizers
- Debug and improve neural network training

## Getting Started
1. Start with `L07_Training_NNs.ipynb` to learn neural network training fundamentals
2. Practice with the hands-on exercises in the main notebook
3. Explore additional examples in `Week_7_Backprop.ipynb` (voluntary)
