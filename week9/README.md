# Week 9: Decision Trees

## Overview
This week focuses on Decision Trees, one of the most intuitive and interpretable machine learning algorithms. You'll learn about tree-based models, understand how they split data, and explore advanced topics like overfitting and Random Forests.

## Files

- **L09_Decision_Trees.ipynb**: Main lab notebook covering decision tree concepts and implementation
- **Week 9 Decision trees.ipynb**: Additional examples and decision tree fundamentals (optional)
- **Week 9 Decision trees overfitting and random forest.ipynb**: Advanced topics covering overfitting prevention and Random Forest ensembles (optional)

## Open directly the lab in Google Colab

<a href="https://colab.research.google.com/github/zhaw-physical-ai/MLDM_HS2025/blob/main/week9/L09_Decision_Trees.ipynb" target="_blank">
  <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open Main Lab File In Colab" width="200"/>
</a><br></br>

For the additional notebooks with examples:

[![Run additional (voluntary) Decision Trees notebook](https://img.shields.io/badge/Colab-Run%20additional%20(voluntary)%20Decision%20Trees%20notebook-orange?logo=googlecolab)](https://colab.research.google.com/github/zhaw-physical-ai/MLDM_HS2025/blob/main/week9/Week%209%20Decision%20trees.ipynb)

[![Run additional (voluntary) Overfitting and Random Forest notebook](https://img.shields.io/badge/Colab-Run%20additional%20(voluntary)%20Overfitting%20and%20Random%20Forest%20notebook-orange?logo=googlecolab)](https://colab.research.google.com/github/zhaw-physical-ai/MLDM_HS2025/blob/main/week9/Week%209%20Decision%20trees%20overfitting%20and%20random%20forest.ipynb)



## Learning Objectives
- Understand how decision trees make predictions using recursive partitioning
- Learn about splitting criteria (Gini impurity, entropy, information gain)
- Visualize and interpret decision tree structures
- Recognize and address overfitting in decision trees
- Master tree pruning techniques and hyperparameter tuning
- Understand ensemble methods and Random Forests
- Implement decision trees and Random Forests for classification and regression
- Compare decision trees with other machine learning algorithms

## Getting Started
1. Start with `L09_Decision_Trees.ipynb` to learn decision tree fundamentals
2. Practice with the hands-on exercises in the main notebook
3. Explore additional examples in the optional notebooks for deeper understanding
4. Work through the Random Forest material to learn about ensemble methods
