{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1w-jpwcxOyH2CKWa5S-NNOyRCVFTbWJ5T","timestamp":1697052534087}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"pAJRKdv9QA4C"},"outputs":[],"source":["import numpy as np\n","import os\n","from matplotlib import pyplot as plt"]},{"cell_type":"markdown","source":["In this lab you will apply logistic regression to a dataset of images with the goal of classifying each image as a smile (1) or non-smile (0). We are using a dataset of faces called GENKI.\n","First, we  download the dataset and explore it.\n","\n"],"metadata":{"id":"u0XcV69YcQhk"}},{"cell_type":"code","source":["# Download dataset\n","# Note: this only needs to be done once!\n","if not os.path.exists(\"trainingLabels.npy\"):\n","  !wget https://s3.amazonaws.com/jrwprojects/trainingLabels.npy\n","  !wget https://s3.amazonaws.com/jrwprojects/testingLabels.npy\n","  !wget https://s3.amazonaws.com/jrwprojects/trainingFaces.npy\n","  !wget https://s3.amazonaws.com/jrwprojects/testingFaces.npy"],"metadata":{"id":"wR0ijS0VZ6dk"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1fd78190-5445-4c53-9b7f-4a0f7aeaf87c"},"outputs":[],"source":["# Load dataset\n","trainingFaces = np.load(\"trainingFaces.npy\")\n","trainingLabels = np.load(\"trainingLabels.npy\")\n","testingFaces = np.load(\"testingFaces.npy\")\n","testingLabels = np.load(\"testingLabels.npy\")\n","# Print out the dimensions of the arrays\n","print(\"trainingFaces shape: \", trainingFaces.shape)\n","print(\"trainingLabels shape: \", trainingLabels.shape)\n","print(\"testingFaces shape: \", testingFaces.shape)\n","print(\"testingLabels shape: \", testingLabels.shape)\n","# Print out basic statistics\n","print(\"Proportion 'smile' in training:\", trainingLabels.mean())  # Proportion of training faces that are \"smile\"\n","print(\"Proportion 'smile' in testing:\", testingLabels.mean())  # Proportion of testing faces that are \"smile\""]},{"cell_type":"markdown","source":["The labels are binary (1 = smile, 0 = non-smile). The images are stored as arrays of grayscale pixel values (each image contains 24*24 = 576 total pixels)."],"metadata":{"id":"a6SQliB0P4h_"}},{"cell_type":"markdown","source":["Let's visualize some of the faces. We first have to reshape each image from a 576-dimensional vector (which is convenient for classification with logistic regression) to a 24x24 array (which is convenient for visualization):"],"metadata":{"id":"_9FX76IifOik"}},{"cell_type":"code","source":["for i in range(5):\n","  # Before rendering, we have to reshape the image vector into a 2-d array\n","  fig, ax = plt.subplots(figsize=(1.25, 1.25))\n","  ax.imshow(trainingFaces[i,:].reshape(24, 24), cmap='gray')\n","  plt.show()\n","  print(\"label: \", trainingLabels[i])"],"metadata":{"id":"49r9vxwHQ6pE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["In most of the images, the label (smile vs. non-smile) is quite clear. However, in some it is not. Examine the 4 images below, and ask yourself: how would *you* classify them? (Note: you do not need to answer on Moodle.)"],"metadata":{"id":"PQwfoiQC8mR_"}},{"cell_type":"code","source":["ambiguousIdxs = [ 187, 192, 566, 1401 ]\n","for idx in ambiguousIdxs:\n","  fig, ax = plt.subplots(figsize=(1.25, 1.25))\n","  ax.imshow(testingFaces[idx,:].reshape(24, 24), cmap='gray')\n","  plt.show()"],"metadata":{"id":"OL9Px1wh8wP4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Task 1a: Logistic Regression for Smile Classification (1 Point)\n","\n","**Your task**: Train a logistic regression classifier (use the LogisticRegression class in sklearn) on the entire training dataset, and measure its accuracy (proportion of correctly classified images) on  the testing data."],"metadata":{"id":"vqNWZixl2g-2"}},{"cell_type":"code","source":["import sklearn.linear_model\n","\n","logisticRegressor = sklearn.linear_model.LogisticRegression(max_iter=500)\n","# TODO: implement the rest here"],"metadata":{"id":"n3Ac-KAD2s8l"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["游닉 **HAND-IN** 游닉:\n","Enter the testing accuracy of the trained model on Moodle."],"metadata":{"id":"UM5T-7au4CPx"}},{"cell_type":"markdown","metadata":{"id":"fDgGTbTMHxwN"},"source":["## Task 1b: Measure the Effect of Training Set Size on Training & Testing Accuracies (4 pts)\n","As a general rule: the more training data you have, the higher your testing accuracy will be. In this next task, you will explore this issue quantitatively.\n","\n","**Your task**: Using the provided training and test data, experiment with how the size of the training set impacts the test accuracy. In particular, vary M over 100, 200, 300, ..., 2000. For each M, train a logistic regression classifier  containing M training examples (just use the first M examples) to recognize a smile (1) or non-smile (0). Then, measure *training* accuracy of the trained classifier (i.e., just the M examples you actually trained on) as well as the *test* accuracy (proportion of examples classified correctly). Plot these two curves in the same plot as a function of M. Why do you think the curves look the way they do?"]},{"cell_type":"code","source":["import sklearn.linear_model\n","\n","trainingAccuracies = []\n","testingAccuracies = []\n","Mvalues = np.arange(100, 2001, 100)\n","for M in Mvalues:\n","  logisticRegressor = sklearn.linear_model.LogisticRegression(max_iter=500)\n","  # TODO: implement the rest here\n","  # ...\n","\n","  trainingAccuracies.append(0)  # TODO: change this\n","  testingAccuracies.append(0)  # TODO: change this\n","\n","plt.plot(Mvalues, trainingAccuracies)\n","plt.plot(Mvalues, testingAccuracies)\n","plt.legend([ \"Training\", \"Testing\" ])\n","plt.show()"],"metadata":{"id":"Flqu_hbORatr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["游닉 **HAND-IN** 游닉:\n","On Moodle, upload your plot."],"metadata":{"id":"O-Q0LeFbTExa"}},{"cell_type":"markdown","source":["## Task 2a: Examining the \"Worst\" Mistakes (2 pts)\n","You can sometimes learn something  about both the dataset and a trained model by examining its \"worst\"  mistakes, i.e., examples on which the model is *highly confident* but *wrong*.  For this purpose, you can call the LogisticRegressor.predict_proba function, which returns a probability in the interval (0,1) rather than a binary prediction.\n","\n","**Your task**:\n","Find the top 25 *positively-labeled* examples in the test set on which the trained classifier (using M=2000) was *most confident* but *wrong*, i.e., yhat nearest to 0. Show these images and the machine's probability estimate yhat. Do the same thing for the top 25 *negatively-labeled* examples in the test set on which yhat was closest to 1.\n","\n","What do you observe about these particular examples and their labels?"],"metadata":{"id":"5EUvBPh85E8Q"}},{"cell_type":"code","source":["# Utility method to plot the faces whose indices are specified in idxs\n","def show (idxs):\n","  for idx in idxs:\n","    fig, ax = plt.subplots(figsize=(1.25, 1.25))\n","    ax.imshow(testingFaces[idx,:].reshape(24,24), cmap='gray')\n","    plt.show()\n","    print(testingLabels[idx], yhat[idx])"],"metadata":{"id":"WhEVeKx4bbIG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# In the line below, \",1\" picks out the probability of the positive class (smile)\n","yhat = logisticRegressor.predict_proba(testingFaces)[:,1]\n","\n","print(\"Positive\")\n","# TODO: find the top 25 least worst mistakes for the positive examples\n","show(idxs)\n","print(\"Negative\")\n","# TODO: find the top 25 least worst mistakes for the negative examples\n","show(idxs)"],"metadata":{"id":"PpMSSjsu6caj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["游닉 **HAND-IN** 游닉:\n","On Moodle, offer an explanation (referring to specific attributes of the faces, e.g., eye-glasses, lighting, etc.) about why those particular images were highly confident but incorrectly classified."],"metadata":{"id":"8JOkEpeQ7wIc"}},{"cell_type":"markdown","source":["## Task 2b: Finding Least Confidently Predicted Examples\n","It can be instructive to find examples on which the trained classifier is uncertain/not confident. For this purpose, you can call the LogisticRegressor.predict_proba, which returns a probability in the interval (0,1) rather than a binary probability.\n","\n","**Your task**:\n","Find the top 25 examples in the test set on which the trained classifier (using M=2000) was *least confident* (i.e., yhat closest to 0.5) in its prediction. Show these images, the machine's probabilistic prediction, and the true label. Do you see any reason why those images might cause the machine some \"confusion\"? (Note: there may not be an obvious answer, but you can still speculate.)"],"metadata":{"id":"FAOcTpxehVy4"}},{"cell_type":"code","source":["# TODO: find 25 least confidently predicted examples"],"metadata":{"id":"u89Imu-9iPFb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["You do not need to submit anything on Moodle for this task."],"metadata":{"id":"2jLd-NMmE7eU"}},{"cell_type":"markdown","source":["# Task 3: Data Augmentation (3 pts)\n","A perennial problem in machine learning is the lack of sufficient training data. One way to increase the amount of training data is to use **data augmentation**, i.e., to synthetically create more training examples from the ones that already exist. While this is possible only in certain situations, it can be very powerful. One setting in which it often is possible is when working with images. Face images in particular have a special kind of symmetry: if you \"flip\" a face left-to-right, then the person's facial expression basically remains the same.  This means that, by flipping a face image left-to-right, we can create another face image with the same training label -- *without* having to manually photograph and label that example ourselves.\n","\n","Below is a Python function that takes an array (M x 576) of face images and returns another array of the same size and contents, except that all the images have been flipped left-to-right."],"metadata":{"id":"HkSwv5rjfEiU"}},{"cell_type":"code","source":["def flip (faces):\n","    faces = np.atleast_3d(faces)\n","    faces = faces.reshape(-1, 24, 24)  # convert faces from vectors to 2-d arrays\n","    faces = faces[:, :, ::-1]  # flip all the 2-d arrays left-to-right\n","    return faces.reshape(-1, 24**2)  # convert faces from 2-d arrays to vectors"],"metadata":{"id":"FGVO1c65f33e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Here's an example of an original and a flipped face:"],"metadata":{"id":"ep_0D4edAiBd"}},{"cell_type":"code","source":["fig, ax = plt.subplots(1, 2, figsize=(2.5, 2.5))\n","ax[0].imshow(trainingFaces[4,:].reshape(24, 24), cmap='gray')\n","ax[1].imshow(flip(trainingFaces[4,:]).reshape(24, 24), cmap='gray')\n","plt.show()"],"metadata":{"id":"ZRYzpkfY_wML"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Your task**: Using the flip function, try training on a larger dataset: the original training set was just 2000 images, but with this data augmentation technique, we can get up to 4000 images. Does training on this larger dataset improve testing accuracy? Create a plot similar to the one you made for Task 1b, but this time vary M up to 4000."],"metadata":{"id":"-Vo860_8ApLZ"}},{"cell_type":"code","source":["# TODO: apply data augmentation and create plot, similar to Task 1b."],"metadata":{"id":"F6TWnwfCgHi0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["游닉 **HAND-IN** 游닉:\n","On Moodle, upload your plot (where M ranges up to 4000)."],"metadata":{"id":"iY7MCt12gYO2"}},{"cell_type":"markdown","source":["# Task 4: Pushing the Limits (4 pts)\n","Now that you've trained a logistic regression classifier on this task, see how far you can \"push the limit\" and train as accurate a classifier as possible. This task is open-ended: you can try hyperparameter optimization, new forms of data augmentation, or other techniques.\n","\n","*Hyperparameter tuning*: You may be able to increase the accuracy by optimizing the amount of regularization. In sklearn, the regularization strength of the logistic regression classifier can be tuned by setting the C parameter in the constructor of LogisticRegression. To optimize hyperparameters in a principled way, we need three data sets: training, validation, and testing. However, the data you are provided with contains just training and testing sets. Hence, you should sub-divide the training data into two subsets: \"real\" training (this is what you call fit() on), and validation (which you use to estimate how good each hyperparameter configuration is). As a suggestion, try using 80% of trainingFaces and trainingLabels for training, and the remaining 20% for validation.\n","\n","*Data augmentation*: In addition to left-right flips, you can also try adding a small amount of (typically Gaussian) random noise to each pixel (using a small standard deviation of the Gaussian distribution, so that the face images still looks like a face). See np.random.randn. In order to avoid manually overfitting to the test data, you should also experiment with different forms of data augmentation on a separate validation set; then, once you find a good method of augmentation, test out the resulting classifier on the testing set."],"metadata":{"id":"dDuVe8Ov9_zM"}},{"cell_type":"markdown","source":["游닉 **HAND-IN** 游닉:\n","On Moodle, upload your code above, and report the final testing accuracy."],"metadata":{"id":"_plSREBMIGU4"}}]}